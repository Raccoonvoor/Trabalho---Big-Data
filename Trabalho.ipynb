{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240c5db-92e0-4ffb-ae5f-3e0d6bd582d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r Requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cca2bb3-202e-4d4a-a3d6-c899316e6ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öô Configura√ß√£o:\n",
      "   -> Cache Tempor√°rio: /home/jovyan/datasets/kaggle_cache\n",
      "   -> Destino MongoDB: mongo_service:27017/?authSource=admin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# 1. IMPORTA√á√ïES E CONFIGURA√á√ÉO (Executar Primeiro)\n",
    "# =================================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# üìÇ CONFIGURA√á√ÉO CR√çTICA DE DISCO\n",
    "# Aponta o cache de download para a pasta mapeada no Docker (seu HD f√≠sico).\n",
    "# Isso evita o erro \"No space left on device\" da VM.\n",
    "CACHE_DIR = '/home/jovyan/datasets/kaggle_cache'\n",
    "os.environ['KAGGLEHUB_CACHE'] = CACHE_DIR\n",
    "\n",
    "# üîå CONFIGURA√á√ÉO DO MONGODB\n",
    "# Usa o nome do servi√ßo 'mongo_service' definido no docker-compose\n",
    "MONGO_URI = \"mongodb://root:mongo@mongo_service:27017/?authSource=admin\"\n",
    "DB_NAME = \"SteamRecommendations\"\n",
    "\n",
    "print(f\"‚öô Configura√ß√£o:\")\n",
    "print(f\"   -> Cache Tempor√°rio: {CACHE_DIR}\")\n",
    "print(f\"   -> Destino MongoDB: {MONGO_URI.split('@')[1]}\") # Mostra apenas o host para confirmar\n",
    "\n",
    "# =================================================================\n",
    "# 2. FUN√á√ÉO DE INGEST√ÉO (CARGA EM LOTES)\n",
    "# =================================================================\n",
    "\n",
    "def ingest_file_to_mongo(file_path, collection_name):\n",
    "    \"\"\"L√™ CSV em peda√ßos e envia para o Mongo para economizar RAM.\"\"\"\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DB_NAME]\n",
    "    collection = db[collection_name]\n",
    "    \n",
    "    # Limpa dados antigos para evitar duplica√ß√£o se rodar 2x\n",
    "    collection.drop()\n",
    "    print(f\"\\nüîÑ Processando '{collection_name}'...\")\n",
    "    \n",
    "    chunk_size = 10000 # Processa 10 mil linhas por vez\n",
    "    total_inserted = 0\n",
    "    \n",
    "    try:\n",
    "        # L√™ o arquivo CSV\n",
    "        with pd.read_csv(file_path, chunksize=chunk_size, low_memory=False) as reader:\n",
    "            for chunk in reader:\n",
    "                # Converte para formato JSON (lista de dicion√°rios)\n",
    "                data = chunk.to_dict('records')\n",
    "                if data:\n",
    "                    collection.insert_many(data)\n",
    "                    total_inserted += len(data)\n",
    "                    print(f\"   -> Inseridos: {total_inserted} registros...\", end='\\r')\n",
    "        \n",
    "        print(f\"\\n‚úÖ Conclu√≠do: {total_inserted} documentos na cole√ß√£o '{collection_name}'.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erro ao processar {collection_name}: {e}\")\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "# =================================================================\n",
    "# 3. EXECU√á√ÉO DO PIPELINE\n",
    "# =================================================================\n",
    "\n",
    "def run_etl(): #def run_etl(custom_path: str, file_map: dict)\n",
    "    print(\"‚¨á 1. Baixando dados do Kaggle (Isso pode levar alguns minutos)...\")\n",
    "    try:\n",
    "        # O download vai para a pasta ./datasets do seu PC\n",
    "        path = kagglehub.dataset_download(\"antonkozyriev/game-recommendations-on-steam\") #kagglehub.dataset_download(custom_path) #\n",
    "        print(f\"üìÇ Dados baixados em: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro no download: {e}\")\n",
    "        print(\"Dica: Verifique se a pasta ./datasets est√° mapeada corretamente no docker-compose.\")\n",
    "        return\n",
    "\n",
    "    # Lista de arquivos para importar\n",
    "    files_map = { \n",
    "        'games.csv': 'games',\n",
    "        'users.csv': 'users',\n",
    "        'recommendations.csv': 'recommendations'\n",
    "    }\n",
    "    #files_map = file_map\n",
    "    print(\"\\nüöÄ 2. Enviando para o MongoDB...\")\n",
    "    \n",
    "    for csv_file, col_name in files_map.items():\n",
    "        full_path = os.path.join(path, csv_file)\n",
    "        if os.path.exists(full_path):\n",
    "            ingest_file_to_mongo(full_path, col_name)\n",
    "        else:\n",
    "            print(f\"‚ö† Arquivo {csv_file} n√£o encontrado.\")\n",
    "\n",
    "    # Valida√ß√£o Final\n",
    "    print(\"\\nüìä 3. Verifica√ß√£o Final do Banco de Dados:\")\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DB_NAME]\n",
    "    for col in db.list_collection_names():\n",
    "        count = db[col].count_documents({})\n",
    "        print(f\"   üìÅ {col}: {count:,} documentos\")\n",
    "    client.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a86f85-604c-4246-9f87-5d0baa098668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨á 1. Baixando dados do Kaggle (Isso pode levar alguns minutos)...\n",
      "Download already complete (692315526 bytes).\n",
      "Extracting files...\n",
      "üìÇ Dados baixados em: /home/jovyan/datasets/kaggle_cache/datasets/antonkozyriev/game-recommendations-on-steam/versions/28\n",
      "\n",
      "üöÄ 2. Enviando para o MongoDB...\n",
      "\n",
      "üîÑ Processando 'games'...\n",
      "   -> Inseridos: 50872 registros...\n",
      "‚úÖ Conclu√≠do: 50872 documentos na cole√ß√£o 'games'.\n",
      "\n",
      "üîÑ Processando 'users'...\n",
      "   -> Inseridos: 14306064 registros...\n",
      "‚úÖ Conclu√≠do: 14306064 documentos na cole√ß√£o 'users'.\n",
      "\n",
      "üîÑ Processando 'recommendations'...\n",
      "   -> Inseridos: 41154794 registros...\n",
      "‚úÖ Conclu√≠do: 41154794 documentos na cole√ß√£o 'recommendations'.\n",
      "\n",
      "üìä 3. Verifica√ß√£o Final do Banco de Dados:\n",
      "   üìÅ games: 50,872 documentos\n",
      "   üìÅ users: 14,306,064 documentos\n",
      "   üìÅ recommendations: 41,154,794 documentos\n"
     ]
    }
   ],
   "source": [
    "run_etl() #run_etl(\"antonkozyriev/game-recommendations-on-steam\", file_map = {'games.csv': 'games','users.csv': 'users','recommendations.csv': 'recommendations'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e88437-a343-4bf7-9814-d9a42deedfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"games.csv\"\n",
    "pd.read_csv(path, engine='python', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833349b-504d-40ee-816e-2b4f2321af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# 1. IMPORTA√á√ïES E CONFIGURA√á√ÉO (Executar Primeiro)\n",
    "# =================================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# üìÇ CONFIGURA√á√ÉO CR√çTICA DE DISCO\n",
    "# Aponta o cache de download para a pasta mapeada no Docker (seu HD f√≠sico).\n",
    "# Isso evita o erro \"No space left on device\" da VM.\n",
    "CACHE_DIR = '/home/jovyan/datasets/kaggle_cache'\n",
    "os.environ['KAGGLEHUB_CACHE'] = CACHE_DIR\n",
    "\n",
    "# üîå CONFIGURA√á√ÉO DO MONGODB\n",
    "# Usa o nome do servi√ßo 'mongo_service' definido no docker-compose\n",
    "MONGO_URI = \"mongodb://root:mongo@mongo_service:27017/?authSource=admin\"\n",
    "DB_NAME = \"backloggd_raw\"\n",
    "\n",
    "print(f\"‚öô Configura√ß√£o:\")\n",
    "print(f\"   -> Cache Tempor√°rio: {CACHE_DIR}\")\n",
    "print(f\"   -> Destino MongoDB: {MONGO_URI.split('@')[1]}\") # Mostra apenas o host para confirmar\n",
    "\n",
    "# =================================================================\n",
    "# 2. FUN√á√ÉO DE INGEST√ÉO (CARGA EM LOTES)\n",
    "# =================================================================\n",
    "\n",
    "def ingest_file_to_mongo(file_path, collection_name):\n",
    "    \"\"\"L√™ CSV em peda√ßos e envia para o Mongo para economizar RAM.\"\"\"\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DB_NAME]\n",
    "    collection = db[collection_name]\n",
    "    \n",
    "    # Limpa dados antigos para evitar duplica√ß√£o se rodar 2x\n",
    "    collection.drop()\n",
    "    print(f\"\\nüîÑ Processando '{collection_name}'...\")\n",
    "    \n",
    "    chunk_size = 50000 # Processa 50 mil linhas por vez\n",
    "    total_inserted = 0\n",
    "    \n",
    "    try:\n",
    "        # L√™ o arquivo CSV\n",
    "        with pd.read_csv(file_path, chunksize=chunk_size, low_memory=False) as reader:\n",
    "            for chunk in reader:\n",
    "                # Converte para formato JSON (lista de dicion√°rios)\n",
    "                data = chunk.to_dict('records')\n",
    "                \n",
    "                if data:\n",
    "                    collection.insert_many(data)\n",
    "                    total_inserted += len(data)\n",
    "                    print(f\"   -> Inseridos: {total_inserted} registros...\", end='\\r')\n",
    "        \n",
    "        print(f\"\\n‚úÖ Conclu√≠do: {total_inserted} documentos na cole√ß√£o '{collection_name}'.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erro ao processar {collection_name}: {e}\")\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "# =================================================================\n",
    "# 3. EXECU√á√ÉO DO PIPELINE\n",
    "# =================================================================\n",
    "\n",
    "def run_etl():\n",
    "    print(\"‚¨á 1. Baixando dados do Kaggle (Isso pode levar alguns minutos)...\")\n",
    "    try:\n",
    "        # O download vai para a pasta ./datasets do seu PC\n",
    "        path = kagglehub.dataset_download(\"gsimonx37/backloggd\")\n",
    "        print(f\"üìÇ Dados baixados em: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro no download: {e}\")\n",
    "        print(\"Dica: Verifique se a pasta ./datasets est√° mapeada corretamente no docker-compose.\")\n",
    "        return\n",
    "\n",
    "    # Lista de arquivos para importar\n",
    "    files_map = {\n",
    "        'games.csv': 'games',\n",
    "        'developers.csv': 'developers',\n",
    "        'platforms.csv': 'platforms',\n",
    "        'genres.csv': 'genres',\n",
    "        'scores.csv': 'scores' # Arquivo grande\n",
    "    }\n",
    "\n",
    "    print(\"\\nüöÄ 2. Enviando para o MongoDB...\")\n",
    "    \n",
    "    for csv_file, col_name in files_map.items():\n",
    "        full_path = os.path.join(path, csv_file)\n",
    "        if os.path.exists(full_path):\n",
    "            ingest_file_to_mongo(full_path, col_name)\n",
    "        else:\n",
    "            print(f\"‚ö† Arquivo {csv_file} n√£o encontrado.\")\n",
    "\n",
    "    # Valida√ß√£o Final\n",
    "    print(\"\\nüìä 3. Verifica√ß√£o Final do Banco de Dados:\")\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DB_NAME]\n",
    "    for col in db.list_collection_names():\n",
    "        count = db[col].count_documents({})\n",
    "        print(f\"   üìÅ {col}: {count:,} documentos\")\n",
    "    client.close()\n",
    "\n",
    "# Roda o script\n",
    "if _name_ == \"_main_\":\n",
    "    run_etl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
