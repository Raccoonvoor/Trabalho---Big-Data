# Trabalho Big Data  

**1. Estrutura de Pastas do Reposit√≥rio**
```
steam-bigdata-pipeline/
‚îÇ
‚îú‚îÄ‚îÄ data/                   # (Ignorado pelo Git) Onde os dados brutos ficam
‚îÇ   ‚îî‚îÄ‚îÄ kaggle_cache/       # Mapeado para o container Jupyter
‚îÇ
‚îú‚îÄ‚îÄ notebooks/              # Seus scripts de an√°lise e ETL
‚îÇ   ‚îî‚îÄ‚îÄ SteamData.ipynb  # O c√≥digo que voc√™ forneceu vai aqui
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml      # A orquestra√ß√£o de toda a infraestrutura
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias do Python
‚îú‚îÄ‚îÄ README.md               # A documenta√ß√£o principal do projeto
‚îî‚îÄ‚îÄ .gitignore              # Para n√£o subir arquivos pesados (CSV)
```
**2. O Arquivo docker-compose.yml (A Infraestrutura)**

Este √© o cora√ß√£o do projeto. Ele sobe o Jupyter, o Mongo, o MinIO e o Metabase, conectando todos na mesma rede.
Crie um arquivo chamado docker-compose.yml na raiz:

version: '3.3'

services:
**# 1. JUPYTER LAB (Onde roda o c√≥digo Python)**

**docker-compose.yml do Jupyter (ETL e Processamento).**
```
version: '3.3'

services:

  jupyter:
    build:
      context: . # Manda o Docker construir a imagem a partir de um Dockerfile (n√£o mostrado) na pasta atual.
    ports:
      - "8888:8888" # Acessa o Jupyter Notebook em http://localhost:8888.
      # - "4040:4040" # Comentado, mas pronto para Spark UI, indicando escalabilidade futura.
    volumes:
      - ./notebooks:/home/jovyan/work # **CR√çTICO:** Mapeia seus scripts locais para o ambiente de trabalho do Jupyter.
      - ./data:/home/jovyan/data # Mapeamento para o seu c√≥digo salvar ou buscar arquivos.
      - ./config:/home/jovyan/.jupyter # Persist√™ncia de configura√ß√µes do Jupyter.
    networks:
      - mybridge # Conecta o Jupyter √† rede comum para se comunicar com o MongoDB.

networks:
  mybridge: # O Jupyter depende dessa rede.
    external: # **CHAVE:** Declara que a rede j√° deve existir (criada separadamente ou por outro docker-compose).
      name: mybridge

volumes: # Declara√ß√£o dos volumes, embora o mapeamento esteja usando caminhos relativos (./notebooks)
  notebooks:
  data:
  config:
```
Fun√ß√£o: Execu√ß√£o do seu pipeline de ingest√£o e processamento.

Conex√£o: Ele se conecta ao MongoDB usando o nome do servi√ßo mongo (conforme definido no arquivo do MongoDB) atrav√©s da rede mybridge.

**1. Configura√ß√£o e Conex√£o (C√≥digo Essencial)**

Como a aplica√ß√£o se conecta √† infraestrutura Docker e configura o ambiente para lidar com arquivos grandes:
```
1. IMPORTA√á√ïES E CONFIGURA√á√ÉO (Executar Primeiro)
import os
import pandas as pd
import kagglehub
from pymongo import MongoClient
```

**Configura√ß√£o Cr√≠tica de Disco (Volume Mapping)**

O bloco de c√≥digo aborda um problema comum ao lidar com datasets grandes em ambientes conteinerizados: a falta de espa√ßo.
```
# üìÇ CONFIGURA√á√ÉO CR√çTICA DE DISCO
# Aponta o cache de download para a pasta mapeada no Docker (seu HD f√≠sico).
# Isso evita o erro "No space left on device" da VM.
CACHE_DIR = '/home/jovyan/datasets/kaggle_cache'
os.environ['KAGGLEHUB_CACHE'] = CACHE_DIR
```
**Configura√ß√£o do MongoDB (Conex√£o de Servi√ßo)**

Este bloco define como o seu script (rodando no cont√™iner Jupyter) encontra e se autentica no servi√ßo de banco de dados (rodando no cont√™iner MongoDB).
```
# üîå CONFIGURA√á√ÉO DO MONGODB
# Usa o nome do servi√ßo 'mongo_service' definido no docker-compose
MONGO_URI = "mongodb://root:mongo@mongo_service:27017/?authSource=admin"
DB_NAME = "SteamRecommendations"

print(f"‚öô Configura√ß√£o:")
print(f"   -> Cache Tempor√°rio: {CACHE_DIR}")
print(f"   -> Destino MongoDB: {MONGO_URI.split('@')[1]}") # Mostra apenas o host para confirmar
```
**2. Fun√ß√£o de Ingest√£o Otimizada (Chunking)**

A fun√ß√£o abaixo √© a chave para a efici√™ncia, pois l√™ os arquivos CSV em peda√ßos de 10.000 linhas (chunk_size), prevenindo a sobrecarga da mem√≥ria do cont√™iner Jupyter:

2. FUN√á√ÉO DE INGEST√ÉO (CARGA EM LOTES)
```
def ingest_file_to_mongo(file_path, collection_name):
    """L√™ CSV em peda√ßos e envia para o Mongo para economizar RAM."""
    # ... inicializa cliente
    chunk_size = 10000 # Processa 10 mil linhas por vez
    
    try:
        # L√™ o arquivo CSV em peda√ßos
        with pd.read_csv(file_path, chunksize=chunk_size, low_memory=False) as reader:
            for chunk in reader:
                data = chunk.to_dict('records')
                if data:
                    collection.insert_many(data)
                    # ... contagem e feedback
    # ... tratamento de erros
```
**Inicializa√ß√£o e Limpeza (Pr√©-Carga)**
```
client = MongoClient(MONGO_URI)
db = client[DB_NAME]
collection = db[collection_name]

# Limpa dados antigos para evitar duplica√ß√£o se rodar 2x
collection.drop()
print(f"\nüîÑ Processando '{collection_name}'...")
```
**Otimiza√ß√£o de Mem√≥ria (Chunking)**

Esta √© a parte mais importante para um projeto de Big Data, pois resolve o problema de RAM limitada.
```
chunk_size = 10000 # Processa 10 mil linhas por vez
# ...
with pd.read_csv(file_path, chunksize=chunk_size, low_memory=False) as reader:
    for chunk in reader:
        # ... processamento do chunk
```
**Transforma√ß√£o e Carga (ETL)**

Dentro do loop de itera√ß√£o (o cora√ß√£o da fun√ß√£o), o c√≥digo transforma o peda√ßo lido em um formato compat√≠vel com o MongoDB e o insere.
```
for chunk in reader:
                # Converte para formato JSON (lista de dicion√°rios)
                data = chunk.to_dict('records')
                if data:
                    collection.insert_many(data)
                    total_inserted += len(data)
                    print(f"   -> Inseridos: {total_inserted} registros...", end='\r')
```
**Conclus√£o e Robustez do Pipeline**

Este bloco finaliza o processamento de cada cole√ß√£o, garantindo que o pipeline seja robusto (tratamento de falhas) e limpo (libera√ß√£o de recursos).
```
print(f"\n‚úÖ Conclu√≠do: {total_inserted} documentos na cole√ß√£o '{collection_name}'.")
        
    except Exception as e:
        print(f"\n‚ùå Erro ao processar {collection_name}: {e}")
    finally:
        client.close()
```
 **2. MONGODB (Banco NoSQL)**
 ```
version: '3.3'

services:
  mongo:
    image: mongo:4.4-bionic # Vers√£o espec√≠fica, garantindo estabilidade.
    container_name: mongo_service # Nome que voc√™ usa no seu c√≥digo Python para a URI: 'mongo_service'.
    environment: # Credenciais de acesso administrativo.
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: mongo
    ports:
      - "27017:27017" # Porta para acesso externo (opcionalmente).
    volumes:
      - dbdata:/data/db # **CR√çTICO:** Volume nomeado para persistir o banco de dados.
      - ./db-seed:/db-seed # Volume para scripts de inicializa√ß√£o de banco de dados (se houver).
      - ./datasets:/datasets # Volume mapeado para dados (n√£o usado pelo seu c√≥digo Jupyter, mas boa pr√°tica).
    networks:
      - mybridge # O servi√ßo de banco de dados precisa estar na rede.

  mongo-express:
    image: mongo-express:latest # UI para visualizar o MongoDB (muito √∫til para ver as cole√ß√µes).
    container_name: mongo_express_service
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: admin # Vari√°veis de configura√ß√£o do Mongo Express.
      ME_CONFIG_MONGODB_ADMINPASSWORD: pass
      ME_CONFIG_MONGODB_URL: mongodb://root:mongo@mongo:27017/ # URI de conex√£o.
    ports:
      - "8081:8081" # Acessa a UI do Mongo Express em http://localhost:8081.
    networks:
      - mybridge
    depends_on:
      - mongo # Garante que o Mongo suba antes do Mongo Express.
    # O comando wait-for-it.sh √© uma t√©cnica avan√ßada para garantir que o Mongo esteja pronto antes de iniciar o Express.

networks:
  mybridge: # A rede que hospeda os servi√ßos de dados.
    external: true # Redund√¢ncia na declara√ß√£o da rede.

volumes:
  dbdata: # O volume nomeado para persist√™ncia do Mongo.
  db-seed:
```
Fun√ß√£o: Armazenamento e fornecimento dos dados.

Conex√£o: Exp√µe o nome de servi√ßo mongo_service e o host mongo (no Mongo Express) para os outros containers.

**3. METABASE (Visualiza√ß√£o e BI)**
```
version: '3.3'

services:
  metabase:
    image: metabase/metabase:latest # Imagem oficial do Metabase.
    container_name: metabase
    ports:
      - "3000:3000" # Acessa o Metabase em http://localhost:3000.
    environment:
      MB_DB_TYPE: h2 # Configura√ß√£o do banco de dados interno (Metabase armazena suas pr√≥prias configs aqui).
      MB_DB_FILE: /metabase-data/metabase.db
      MB_JETTY_PORT: 3000
    volumes:
      - ./metabase-data:/metabase-data # Persist√™ncia do banco de dados interno do Metabase.
    restart: unless-stopped
    networks:
      - mybridge # **CHAVE:** Conecta o Metabase √† rede comum.

networks:
  mybridge: # O Metabase precisa dessa rede para se conectar ao MongoDB.
    external:
      name: mybridge
```
Fun√ß√£o: Cat√°logo e explora√ß√£o dos dados modelados.

Conex√£o: Voc√™ configurar√° o Metabase manualmente (ap√≥s iniciar) para usar o host mongo (ou mongo_service, dependendo de como voc√™ o nomeou) na porta 27017 dentro da rede mybridge.

  **Steam Recommendations Big Data Pipeline:**
  
O projeto implementa um pipeline de Engenharia de Dados ponta-a-ponta para processar, armazenar e visualizar dados de recomenda√ß√µes de jogos da Steam. O objetivo √© ingerir grandes volumes de dados brutos e transform√°-los em insights visuais.

**Arquitetura do Projeto:**

O projeto utiliza uma arquitetura baseada em microsservi√ßos via Docker:

Ingest√£o & Processamento (Jupyter): Scripts Python baixam dados do Kaggle, realizam a limpeza e o chunking (processamento em lote) para otimiza√ß√£o de mem√≥ria.

**Data Lake/Storage (MongoDB):**

MongoDB: Atua como nosso Data Warehouse NoSQL, armazenando os dados estruturados de Usu√°rios, Jogos e Recomenda√ß√µes.

Visualiza√ß√£o (Metabase): Conectado ao MongoDB para cria√ß√£o de Dashboards e explora√ß√£o de dados.

