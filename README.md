# Trabalho Big Data  

**1. Estrutura de Pastas do Reposit√≥rio**
```
steam-bigdata-pipeline/
‚îÇ
‚îú‚îÄ‚îÄ data/                   # (Ignorado pelo Git) Onde os dados brutos ficam
‚îÇ   ‚îî‚îÄ‚îÄ kaggle_cache/       # Mapeado para o container Jupyter
‚îÇ
‚îú‚îÄ‚îÄ notebooks/              # Seus scripts de an√°lise e ETL
‚îÇ   ‚îî‚îÄ‚îÄ SteamData.ipynb  # O c√≥digo que voc√™ forneceu vai aqui
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml      # A orquestra√ß√£o de toda a infraestrutura
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias do Python
‚îú‚îÄ‚îÄ README.md               # A documenta√ß√£o principal do projeto
‚îî‚îÄ‚îÄ .gitignore              # Para n√£o subir arquivos pesados (CSV)
```
**2. O Arquivo docker-compose.yml (A Infraestrutura)**

Este √© o cora√ß√£o do projeto. Ele sobe o Jupyter, o Mongo, o MinIO e o Metabase, conectando todos na mesma rede.
Crie um arquivo chamado docker-compose.yml na raiz:

version: '3.3'

services:
**# 1. JUPYTER LAB (Onde roda o c√≥digo Python)**

**docker-compose.yml do Jupyter (ETL e Processamento).**
```
version: '3.3'

services:

  jupyter:
    build:
      context: . # Manda o Docker construir a imagem a partir de um Dockerfile (n√£o mostrado) na pasta atual.
    ports:
      - "8888:8888" # Acessa o Jupyter Notebook em http://localhost:8888.
      # - "4040:4040" # Comentado, mas pronto para Spark UI, indicando escalabilidade futura.
    volumes:
      - ./notebooks:/home/jovyan/work # **CR√çTICO:** Mapeia seus scripts locais para o ambiente de trabalho do Jupyter.
      - ./data:/home/jovyan/data # Mapeamento para o seu c√≥digo salvar ou buscar arquivos.
      - ./config:/home/jovyan/.jupyter # Persist√™ncia de configura√ß√µes do Jupyter.
    networks:
      - mybridge # Conecta o Jupyter √† rede comum para se comunicar com o MongoDB.

networks:
  mybridge: # O Jupyter depende dessa rede.
    external: # **CHAVE:** Declara que a rede j√° deve existir (criada separadamente ou por outro docker-compose).
      name: mybridge

volumes: # Declara√ß√£o dos volumes, embora o mapeamento esteja usando caminhos relativos (./notebooks)
  notebooks:
  data:
  config:
```
Fun√ß√£o: Execu√ß√£o do seu pipeline de ingest√£o e processamento.

Conex√£o: Ele se conecta ao MongoDB usando o nome do servi√ßo mongo (conforme definido no arquivo do MongoDB) atrav√©s da rede mybridge.

**NOTEBOOK JUPYTER**

**Configura√ß√£o e Conex√£o (C√≥digo Essencial)**

Como a aplica√ß√£o se conecta √† infraestrutura Docker e configura o ambiente para lidar com arquivos grandes:

**1. IMPORTA√á√ïES E CONFIGURA√á√ÉO (Executar Primeiro)**
```
import os
import pandas as pd
import kagglehub
from pymongo import MongoClient
```

**Configura√ß√£o Cr√≠tica de Disco (Volume Mapping)**

O bloco de c√≥digo aborda um problema comum ao lidar com datasets grandes em ambientes conteinerizados: a falta de espa√ßo.
```
# üìÇ CONFIGURA√á√ÉO CR√çTICA DE DISCO
# Aponta o cache de download para a pasta mapeada no Docker (seu HD f√≠sico).
# Isso evita o erro "No space left on device" da VM.
CACHE_DIR = '/home/jovyan/datasets/kaggle_cache'
os.environ['KAGGLEHUB_CACHE'] = CACHE_DIR
```
**Configura√ß√£o do MongoDB (Conex√£o de Servi√ßo)**

Este bloco define como o seu script (rodando no cont√™iner Jupyter) encontra e se autentica no servi√ßo de banco de dados (rodando no cont√™iner MongoDB).
```
# üîå CONFIGURA√á√ÉO DO MONGODB
# Usa o nome do servi√ßo 'mongo_service' definido no docker-compose
MONGO_URI = "mongodb://root:mongo@mongo_service:27017/?authSource=admin"
DB_NAME = "SteamRecommendations"

print(f"‚öô Configura√ß√£o:")
print(f"   -> Cache Tempor√°rio: {CACHE_DIR}")
print(f"   -> Destino MongoDB: {MONGO_URI.split('@')[1]}") # Mostra apenas o host para confirmar
```
**2. Fun√ß√£o de Ingest√£o Otimizada (Chunking)**

A fun√ß√£o abaixo √© a chave para a efici√™ncia, pois l√™ os arquivos CSV em peda√ßos de 10.000 linhas (chunk_size), prevenindo a sobrecarga da mem√≥ria do cont√™iner Jupyter:
```
def ingest_file_to_mongo(file_path, collection_name):
    """L√™ CSV em peda√ßos e envia para o Mongo para economizar RAM."""
    # ... inicializa cliente
    chunk_size = 10000 # Processa 10 mil linhas por vez
    
    try:
        # L√™ o arquivo CSV em peda√ßos
        with pd.read_csv(file_path, chunksize=chunk_size, low_memory=False) as reader:
            for chunk in reader:
                data = chunk.to_dict('records')
                if data:
                    collection.insert_many(data)
                    # ... contagem e feedback
    # ... tratamento de erros
```
**Inicializa√ß√£o e Limpeza (Pr√©-Carga)**
```
client = MongoClient(MONGO_URI)
db = client[DB_NAME]
collection = db[collection_name]

# Limpa dados antigos para evitar duplica√ß√£o se rodar 2x
collection.drop()
print(f"\nüîÑ Processando '{collection_name}'...")
```
**Otimiza√ß√£o de Mem√≥ria (Chunking)**

Esta √© a parte mais importante para um projeto de Big Data, pois resolve o problema de RAM limitada.
```
chunk_size = 10000 # Processa 10 mil linhas por vez
# ...
with pd.read_csv(file_path, chunksize=chunk_size, low_memory=False) as reader:
    for chunk in reader:
        # ... processamento do chunk
```
**Transforma√ß√£o e Carga (ETL)**

Dentro do loop de itera√ß√£o (o cora√ß√£o da fun√ß√£o), o c√≥digo transforma o peda√ßo lido em um formato compat√≠vel com o MongoDB e o insere.
```
for chunk in reader:
                # Converte para formato JSON (lista de dicion√°rios)
                data = chunk.to_dict('records')
                if data:
                    collection.insert_many(data)
                    total_inserted += len(data)
                    print(f"   -> Inseridos: {total_inserted} registros...", end='\r')
```
**Conclus√£o e Robustez do Pipeline**

Este bloco finaliza o processamento de cada cole√ß√£o, garantindo que o pipeline seja robusto (tratamento de falhas) e limpo (libera√ß√£o de recursos).
```
print(f"\n‚úÖ Conclu√≠do: {total_inserted} documentos na cole√ß√£o '{collection_name}'.")
        
    except Exception as e:
        print(f"\n‚ùå Erro ao processar {collection_name}: {e}")
    finally:
        client.close()
```
orchestrator L√≥gica da Fun√ß√£o run_etl()

A fun√ß√£o run_etl() coordena o fluxo de dados desde a origem (Kaggle) at√© o destino (MongoDB), garantindo que os dados sejam baixados, processados e verificados.

**Extra√ß√£o e Verifica√ß√£o**

Esta √© a fase inicial, respons√°vel por obter os dados brutos da fonte externa (Kaggle).

```
print("‚¨á 1. Baixando dados do Kaggle (Isso pode levar alguns minutos)...")
try:
    path = kagglehub.dataset_download("antonkozyriev/game-recommendations-on-steam") 
    print(f"üìÇ Dados baixados em: {path}")
except Exception as e:
    # ... tratamento de erro
    return
```
**Carga Otimizada**

Esta fase √© a itera√ß√£o principal, onde a Carga de dados (utilizando a l√≥gica de chunking da fun√ß√£o ingest_file_to_mongo) √© disparada para cada arquivo CSV.
```
files_map = { 
    'games.csv': 'games',
    'users.csv': 'users',
    'recommendations.csv': 'recommendations'
}
print("\nüöÄ 2. Enviando para o MongoDB...")

for csv_file, col_name in files_map.items():
    full_path = os.path.join(path, csv_file)
    if os.path.exists(full_path):
        ingest_file_to_mongo(full_path, col_name)
    else:
        print(f"‚ö† Arquivo {csv_file} n√£o encontrado.")
```
**Valida√ß√£o Final**

Esta etapa garante a qualidade e a completude do processo ELT.
```
print("\nüìä 3. Verifica√ß√£o Final do Banco de Dados:")
client = MongoClient(MONGO_URI)
db = client[DB_NAME]
for col in db.list_collection_names():
    count = db[col].count_documents({})
    print(f"   üìÅ {col}: {count:,} documentos")
client.close()
```
**Comando de Execu√ß√£o do Pipeline**

A linha final do script √© a chamada da fun√ß√£o run_etl(), que √© o ponto de entrada principal para iniciar todo o processo de Extra√ß√£o, Carga e Valida√ß√£o.
```
run_etl()

```
 **2. MONGODB (Banco NoSQL)**
 ```
version: '3.3'

services:
  mongo:
    image: mongo:4.4-bionic # Vers√£o espec√≠fica, garantindo estabilidade.
    container_name: mongo_service # Nome que voc√™ usa no seu c√≥digo Python para a URI: 'mongo_service'.
    environment: # Credenciais de acesso administrativo.
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: mongo
    ports:
      - "27017:27017" # Porta para acesso externo (opcionalmente).
    volumes:
      - dbdata:/data/db # **CR√çTICO:** Volume nomeado para persistir o banco de dados.
      - ./db-seed:/db-seed # Volume para scripts de inicializa√ß√£o de banco de dados (se houver).
      - ./datasets:/datasets # Volume mapeado para dados (n√£o usado pelo seu c√≥digo Jupyter, mas boa pr√°tica).
    networks:
      - mybridge # O servi√ßo de banco de dados precisa estar na rede.

  mongo-express:
    image: mongo-express:latest # UI para visualizar o MongoDB (muito √∫til para ver as cole√ß√µes).
    container_name: mongo_express_service
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: admin # Vari√°veis de configura√ß√£o do Mongo Express.
      ME_CONFIG_MONGODB_ADMINPASSWORD: pass
      ME_CONFIG_MONGODB_URL: mongodb://root:mongo@mongo:27017/ # URI de conex√£o.
    ports:
      - "8081:8081" # Acessa a UI do Mongo Express em http://localhost:8081.
    networks:
      - mybridge
    depends_on:
      - mongo # Garante que o Mongo suba antes do Mongo Express.
    # O comando wait-for-it.sh √© uma t√©cnica avan√ßada para garantir que o Mongo esteja pronto antes de iniciar o Express.

networks:
  mybridge: # A rede que hospeda os servi√ßos de dados.
    external: true # Redund√¢ncia na declara√ß√£o da rede.

volumes:
  dbdata: # O volume nomeado para persist√™ncia do Mongo.
  db-seed:
```
Fun√ß√£o: Armazenamento e fornecimento dos dados.

Conex√£o: Exp√µe o nome de servi√ßo mongo_service e o host mongo (no Mongo Express) para os outros containers.

**3. METABASE (Visualiza√ß√£o e BI)**
```
version: '3.3'

services:
  metabase:
    image: metabase/metabase:latest # Imagem oficial do Metabase.
    container_name: metabase
    ports:
      - "3000:3000" # Acessa o Metabase em http://localhost:3000.
    environment:
      MB_DB_TYPE: h2 # Configura√ß√£o do banco de dados interno (Metabase armazena suas pr√≥prias configs aqui).
      MB_DB_FILE: /metabase-data/metabase.db
      MB_JETTY_PORT: 3000
    volumes:
      - ./metabase-data:/metabase-data # Persist√™ncia do banco de dados interno do Metabase.
    restart: unless-stopped
    networks:
      - mybridge # **CHAVE:** Conecta o Metabase √† rede comum.

networks:
  mybridge: # O Metabase precisa dessa rede para se conectar ao MongoDB.
    external:
      name: mybridge
```
Fun√ß√£o: Cat√°logo e explora√ß√£o dos dados modelados.

Conex√£o: Voc√™ configurar√° o Metabase manualmente (ap√≥s iniciar) para usar o host mongo (ou mongo_service, dependendo de como voc√™ o nomeou) na porta 27017 dentro da rede mybridge.

  **Steam Recommendations Big Data Pipeline:**
  
O projeto implementa um pipeline de Engenharia de Dados ponta-a-ponta para processar, armazenar e visualizar dados de recomenda√ß√µes de jogos da Steam. O objetivo √© ingerir grandes volumes de dados brutos e transform√°-los em insights visuais.

**Arquitetura do Projeto:**

O projeto utiliza uma arquitetura baseada em microsservi√ßos via Docker:

Ingest√£o & Processamento (Jupyter): Scripts Python baixam dados do Kaggle, realizam a limpeza e o chunking (processamento em lote) para otimiza√ß√£o de mem√≥ria.

**Data Lake/Storage (MongoDB):**

MongoDB: Atua como nosso Data Warehouse NoSQL, armazenando os dados estruturados de Usu√°rios, Jogos e Recomenda√ß√µes.

Visualiza√ß√£o (Metabase): Conectado ao MongoDB para cria√ß√£o de Dashboards e explora√ß√£o de dados.

Utilizei o comando: **docker ps** para poder listar todos os containers na minha aplica√ß√£o.
<img width="1312" height="111" alt="image" src="https://github.com/user-attachments/assets/bd53fbe4-3162-4336-99d7-7ab523f62fa3" />

Utilizei o comando: **docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' <CONTAINER_NAME_OR_ID>**
Para obter **<CONTAINER_NAME_OR_ID>**. Para no fim utilizar **docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}'** mongo_service para encontrar o endere√ßo ip
<img width="971" height="35" alt="image" src="https://github.com/user-attachments/assets/6fea60d7-325e-4c79-bd3d-750358cccb31" />

Como fiz no metabase:

<img width="1918" height="967" alt="image" src="https://github.com/user-attachments/assets/d4206c50-0a72-4e38-9966-ee19e6377c96" />




